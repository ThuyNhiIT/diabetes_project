import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# ----------------------------
# ƒê∆∞·ªùng d·∫´n
# ----------------------------
DATA_PATH = Path(__file__).parents[1] / "data" / "diabetes.csv"
MODEL_DIR = Path(__file__).parents[1] / "models"
MODEL_PATH = MODEL_DIR / "xgb_diabetes_model.joblib"
SCALER_PATH = MODEL_DIR / "scaler.joblib"
FEATURES_PATH = MODEL_DIR / "feature_columns.joblib"

# ----------------------------
# Log b·∫Øt ƒë·∫ßu
# ----------------------------
print("üìå Starting training script...")

# ----------------------------
# Load d·ªØ li·ªáu
# ----------------------------
print(f"üìå Loading data from {DATA_PATH}")
df = pd.read_csv(DATA_PATH)
print(f"‚úÖ Data shape: {df.shape}")

# ----------------------------
# X·ª≠ l√Ω missing values
# ----------------------------
df.fillna(df.mean(numeric_only=True), inplace=True)  # numeric
df.fillna('no info', inplace=True)                  # categorical
print("‚úÖ Missing values handled")

# ----------------------------
# X·ª≠ l√Ω c·ªôt categorical
# ----------------------------
categorical_cols = ['gender', 'location', 'smoking_history']  # th√™m c·ªôt kh√°c n·∫øu c·∫ßn
for col in categorical_cols:
    df[col] = df[col].astype(str).str.strip().str.lower()
df = pd.get_dummies(df, columns=categorical_cols, dummy_na=True)
print(f"‚úÖ Categorical columns encoded: {categorical_cols}")

# ----------------------------
# T√°ch features v√† target
# ----------------------------
X = df.drop('diabetes', axis=1)
y = df['diabetes']
print(f"‚úÖ Features shape: {X.shape}, Target shape: {y.shape}")

# ----------------------------
# L∆∞u danh s√°ch c·ªôt features
# ----------------------------
feature_columns = X.columns.tolist()
joblib.dump(feature_columns, FEATURES_PATH)
print(f"‚úÖ Feature columns saved to {FEATURES_PATH}")

# ----------------------------
# Chu·∫©n h√≥a d·ªØ li·ªáu
# ----------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úÖ Numeric features scaled")

# ----------------------------
# Chia train/test
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)
print(f"‚úÖ Train shape: {X_train.shape}, Test shape: {X_test.shape}")

# ----------------------------
# Train XGBoost
# ----------------------------
print("üìå Training XGBoost model...")
model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    random_state=42,
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8
)
model.fit(X_train, y_train)
print("‚úÖ Model training completed")

# ----------------------------
# D·ª± ƒëo√°n v√† ƒë√°nh gi√°
# ----------------------------
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"üìä Accuracy: {accuracy:.4f}")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Diabetes','Diabetes'],
            yticklabels=['No Diabetes','Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ----------------------------
# L∆∞u model v√† scaler
# ----------------------------
joblib.dump(model, MODEL_PATH)
joblib.dump(scaler, SCALER_PATH)
print(f"‚úÖ Model saved to {MODEL_PATH}")
print(f"‚úÖ Scaler saved to {SCALER_PATH}")

print("üéâ Training script finished successfully!")
